---
title: 深度学习分享
date: 2023-10-01 16:34:29
tags:
  - Deep Learning
typora-root-url: ./..
---

深度学习分享：

你怎么不找我说话啊！！！！20231002-15：06

俩小时了，好难熬啊！！！！20231002-17：07

怎么通俗易懂的给从没有接触过深度学习的同事们介绍深度学习，是个让人非常头疼的问题。

<small>为了让各位前辈更迅速更简单的了解深度学习，我将大量的其他信息都进行了过滤，我们只聊最简单最基础最能抓住这些信息的东西，所有我对大量的内容进行了删除，总结。如果深入理解，有一些说法是不那么正确的。</small>

## 机器学习

机器学习，顾名思义，机器具备有学习的能力。具体来讲，机器学习就是让机器具备找一个函数的能力。

以图像识别为例，图像识别函数的输入是一张图片，输出是这个图片里面的内容。根据要找的函数不同，机器学习有不同的类别。

- 假设要找的函数的输出是一个数值，这种机器学习的任务称为回归。
- 函数的输出就是从设定好的选项里面选择一个当作输出，该任务称为分类。

机器学习找函数的过程，分成3 个步骤。

**第一个步骤**是写出一个带有未知参数的函数$f$，其能预测未来点击次数。比如将函数写成
$$
y = b + wx_1
$$
其中$y$是要预测的东西，$x_1$是输入的数据，而$w$跟$b$是未知的，$w$称为权重，$b$称为偏置。

**第二个步骤**是定义损失（loss），损失也是一个函数。这个函数的输入是模型里面的参数，模型是$y = b + w ∗ x1$，而$b $跟$w $是未知的，损失是函数$L(b,w)$，其输入是模型参数$b $跟$w$，假设真是的结果是$\hat{y}$。

每一个数据的预测差距可以这么表示：
$$
e_i=|y-\hat{y}|
$$
把所有数据的差距加起来求平均就是损失：
$$
L=\frac{1}{N} \sum_{n}
$$
**第三个步骤**是找到一个最优解，找到一个$w$跟$b$能让损失尽可能小，让预测的结果跟真实的结果尽可能接近。

![](/imgs/深度学习/损失L.jpg)

w在不同大小的时候会有不同的损失，为了让损失尽可能小，需要先随机找到一个初始点$w^0$，$w^0$就是这个时刻的切线斜率。

把$w0 $往右移一步，新的位置为$w1$，这一步的步伐是$η(学习率) $乘上$L$关于$w$的偏微分的结果就是：
$$
w^1 << w^0-η\frac{\partial{L}}{\partial{w}}|(w=w^0)
$$
接下来反复进行刚才的操作，最终求得最优解。当然这其中有很多策略和其他的知识点，对于我们要简单的了解深度学习来说是不需要探讨的。

所以各位前辈大概已经清楚了机器学习损失反向传播的一种大致思维，这种反复对损失进行优化的过程，我们就把他简单的看成一个训练过程。

## 深度学习

对于我们简单的了解深度学习来说，我们这里不讨论：过拟合、优化问题、交叉验证、局部极小值与鞍点、批量与动量、自适应与学习率。我们从全局来了解深度学习网络方便我们对CAI（生成式AI有所了解）。

深度学习是机器学习的一个分支(最重要的分支)，我们之前假设机器学习就是简单的一个函数处理优化流程，这只是我总结的一个大貌，但各位前辈们如果有意深入了解会发现机器学习包含很多东西，我的总结也并不全对。

这里我们假设深度学习是要处理信息的“水流”，处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。

这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。

而这一个一个的小水管都是可控制他们的水流速度，水流体积。我们也可以把每一个水管都当作一个函数，控制水流就靠w和b，而这些一个一个小函数，小的神经单元组成一个大的函数，大的神经网络。

![](/imgs/深度学习/深度网络.png)

那么这么复杂的网络它带来的第一个优势就是他的学习能力强，表示覆盖的范围广，也同事让深度学习对计算量这些要求比较高。

## 卷积神经网络

我们从卷积神经网络（Convolutional Neural Network，CNN）开始，探讨网络的架构设计。卷积神经网络是一种非常典型的网络架构，常用于图像的处理等任务。

对于卷积神经网络来说，我们不考虑池化下采样、上采样、反向传播这些内容，仅仅是了解它大致的一个处理思路。

我们从一个图像分类任务入手，所谓图像分类，就是给机器一张图像，由机器去判断这张图像里面有什么样的东西——是猫还是狗、是飞机还是汽车。

而怎么把图像作为模型的输入呢？？对于机器，图像可以描述为三维张量（我们可以把这个张量看作一个浮点型多维矩阵，存储在Double类型的数组里）。一张图像是一个三维的张量，其中一维代表图像的宽，另外一维代表图像的高，还有一维代表图像的通道（channel）的数目。

<small>channel是什么：彩色图像的每个像素都可以描述为红色（red）、绿色（green）、蓝色（blue）的组合，这3 种颜色就称为图像的3 个色彩通.</small>

![](/imgs/深度学习/图像输入.jpg)

我们可以看到把一个100$\times$100像素的图片分解为rgb三个通道后，再把每个像素看成一个元素$x_i$，将这些元素展开拉平到一个1维数组中去，这个数组大小就是100$\times$100$\times$3。

![](/imgs/深度学习/CNN输入到网络.jpg)

对一个图像识别的类神经网络里面的神经元（每个水龙头）而言，它要做的就是检测图像里面有没有出现一些特别重要的模式（pattern），这些模式是代表了某种物件的。

举例来说，如果现在有三个神经元分别看到鸟嘴、眼睛、鸟爪3 个模式，这就代表类神经网络看到了一只鸟。

![](/imgs/深度学习/鸟识别1.jpg)

为了方便大家理解我们可以我用像素画了一只鸟，和一个过滤器来给大家演示。

![](/imgs/深度学习/鸟.png)

我用visio随便画了只鸟，空白的格子我们姑且让他的值为0，右侧的卷积核（水龙头）通过一步步滑动窗口对图像矩阵的元素进行比对。

![image-20231003142939167](/imgs/深度学习/移动1)

![image-20231003143036998](/imgs/深度学习/移动2)

最终找到极其相似的值，如下图所示：

![image-20231003143105899](/imgs/深度学习/移动3)

这样就是卷积神经网络的滑动窗口，它像人一样，在识别或观察一个物体时从细微着手慢慢扫描。我们可以把这么一个卷积核作为一个水龙头，那么他同时就对应我们在机器学习介绍的一个函数，所以这个卷积核的权重也是可以学习的。

对于卷积神经网络我想大家也只是明白了一个大致的流程，但我想这就够了，因为对于任何一个模型我们要深入都要花费很长的时间，而我也只能描述一些大概。来方便各位前辈了解CNN。

## 循环神经网络

对于自然语言来说，我们每说一句话，每个单词与单词之间其实是有联系的。每个结果预测的输出结果其实都依赖之前的数据。比如一句话：我想吃饭。饭这个词很多时候是需要依赖前面的谓语。所以一个网络想要处理好自然语言，他是需要记忆功能的。这种有记忆的神经网络称为循环神经网络（Recurrent Neural Network，RNN）。在RNN里面，每一次隐藏层的神经元产生输出的时候，该输出会被存到记忆元（memory cell）中的蓝色方块表示记忆元。下一次有输入时，这些神经元不仅会考虑输入x1, x2，还会考虑存到记忆元里的值。

![](/imgs/深度学习/RNN.jpg)

接下来我简单的介绍一下RNN是怎么工作的。

假如需要判断用户的说话意图，用户说了句“what time is it？”我们需要先对这句话进行分词：

![](/imgs/深度学习/RNN1.gif)

然后按照顺序输入 RNN ，我们先将 “what”作为 RNN 的输入，得到输出「01」

![](/imgs/深度学习/RNN2.gif)

然后，我们按照顺序，将“time”输入到 RNN 网络，得到输出「02」。

这个过程我们可以看到，输入 “time” 的时候，前面 **“what” 的输出也产生了影响**。

![](/imgs/深度学习/RNN3.gif)

以此类推，前面所有的输入都对未来的输出产生了影响，大家可以看到圆形隐藏层中包含了前面所有的颜色。如下图所示：

![](/imgs/深度学习/RNN4.gif)

当我们判断意图的时候，只需要最后一层的输出「05」，如下图所示：

![](/imgs/深度学习/RNN5.gif)

通过上面的例子，我们已经发现，短期的记忆影响较大（如橙色区域），但是长期的记忆影响就很小（如黑色和绿色区域），这就是 RNN 存在的短期记忆问题。

因此对于这些问题有很多RNN的变体，但是我们今天就不介绍了。

## 自注意力机制

Attention（注意力）机制如果浅层的理解，跟他的名字非常匹配。他的核心逻辑就是**“从关注全部到关注重点”**。

Attention 机制很像人类看图片的逻辑，当我们看一张图片的时候，我们并没有看清图片的全部内容，而是将注意力集中在了图片的焦点上。大家看一下下面这张图：

![](/imgs/深度学习/注意力1.png)

我们一定会看清“锦江饭店”4个字，但是我相信没人会意识到“锦江饭店”上面还有一串“电话号码”，也不会意识到“喜运来大酒家”。

![](/imgs/深度学习/注意力.png)

所以，当我们看一张图片的时候，其实是这样的：

![](/imgs/深度学习/注意力2.png)

上面所说的，我们的视觉系统就是一种 Attention机制，**将有限的注意力集中在重点信息上，从而节省资源，快速获得最有效的信息。**

### AI领域注意力机制就是GPT最核心的组件：

如果用图来表达 Attention 的位置大致是下面的样子：

![](/imgs/深度学习/注意力3.png)





注意力机制的优势：

**参数少**：模型复杂度跟 CNN、RNN 相比，复杂度更小，参数也更少。所以对算力的要求也就更小。

**速度快**：Attention 解决了 RNN 不能并行计算的问题。Attention机制每一步计算不依赖于上一步的计算结果，因此可以和CNN一样并行处理。

**效果好**：在 Attention 机制引入之前，有一个问题大家一直很苦恼：长距离的信息会被弱化，就好像记忆能力弱的人，记不住过去的事情是一样的。

Attention 是挑重点，就算文本比较长，也能从中间抓住重点，不丢失重要的信息。下图红色的预期就是被挑出来的重点。

对于注意力的运算来说，其主要原理就是通过对数据集处理，获得三个矩阵，并且生成对应的权重向量，然后对进行相似度计算，之后进行归一化处理，出于对这篇文章最开始目的的把握，所以我不再介绍这些计算。

## Transformer

Transformer在2017年由Google在题为《Attention Is All You Need》的论文中提出。Transformer是一个完全基于注意力机制的编解码器模型，它抛弃了之前其它模型引入注意力机制后仍然保留的循环与卷积结构，而采用了自注意力（Self-attention）机制，在任务表现、并行能力和易于训练性方面都有大幅的提高。

<img src="/imgs/深度学习/Transformer.jpg" style="zoom: 50%;" />

如果CNN、RNN、注意力机制都算是一个基础的组件的话，那么Transformer就是一个模型了

## 生成对抗模型GAN



## ChatGPT

ChatGPT 真正在做的事情是什么呢？一言以蔽之就是做文字“接龙”，正确理解ChatGPT 的方式是它就是一个函数，就是输入一些东西，就输出一些东西。可以以一个句子作为输入，它输出这个句子后面应该接的词汇的概率。它会给每一个可能的符号一个概率。

举例来说，如果输入是“什么是机器学习”，也许下一个可以接的中文词汇，概率比较高的是“机”，然后“器”和“好”也许有一些概率，那其他词汇的概率就很低。ChatGPT输出的是这样一个概率的分布，那ChatGPT 输出概率分布以后，接下来会从这个概率分布里面去做采样，根据这个概率分布去采样出一个词汇。举例来说“机”它的概率是最高的，所以从概率分布里面去采样词汇，采样到“机”的概率可能是比较大的，但也有可能采样到其他的词汇，所以这就是为什么ChatGPT 每次的答案都是不一样的，因为他每次产生答案的时候是有随机性的，它是从一个概率分布里面去做取样，所以他每次的答案都是不同的。

## 深度学习对底软的能力提升：

### 代码生成

### 日志分析

### 代码查错

## GAI对软硬件设计的影响

聊聊**生成式AI(GAI)**对今后[软件设计](https://www.zhihu.com/search?q=软件设计&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})的影响。看了很多业界人士对未来的预测和判断，都感觉有局限性。

这两天在网上看到一篇让人脑洞大开的文章《ChatGPT会在10年内取代程序员》，文章提了两个人们在ChatGPT之类的GAI在软件开发方面的谬误。

- 第一个谬误是“当前的AI会产生bug”，甚至有些代码还不能完全复制粘贴来使用，所以AI不会取代程序员。那么其实人也会产生bug（无论是有意为之还是为了保全工作）。所以有bug的代码并不会阻止GAI最终取代程序员。
- 二个谬误观点是GAI是用来帮助程序员提高效率的工具。那么从老板的角度来看，如果有机器替代的话，高收入的程序员群体是老板眼中首先要节约的“成本”。尤其是因为软件工程是**数字化的，可指数级扩展的工程问题**。这类工作是AI替代的完美目标。

作者对于未来的预测可以这么总结：

阶段0：原型期（2023年第一季度）失业率预测：2%

虽然当前chatGPT还仅仅是基于浏览器的AI工具且并不稳定，但当微软，谷歌以及每个科技和创业公司都想加入竞争的时候，chatGPT类的GAI演进速度会加快。那么当前受影响的是基于搜索的广告业务，[软件工程师](https://www.zhihu.com/search?q=软件工程师&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})还比较安全。

阶段1：规模化的[集成开发环境](https://www.zhihu.com/search?q=集成开发环境&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})（IDE）渗透（2023年第二到第四季度） 失业率预测：5%

这时Copilot，codex及众多的IDE GAI工具将会广泛使用。有大量的Java等语言的样板代码。AI拥有程序上下文分析的能力，GAI将会首先通过微软工具套件等形式被集成。生产力大幅提高，工程速度加快，但项目暂时不会因为提早完成而大量裁员。大多数人还有短暂的安全。

阶段2：高级IDE工具开发与整合（1-2年）失业率预测：25%

该阶段IDE会越来越强大，能分析整个代码库的上下文环境，并提供100%覆盖率的单元测试。编写程序的语言不再重要，用python快速实现的想法，瞬间可以被重写成其他效率更高的代码。真正的**工程清洗( engineering purge)**开始，低效的和拒绝AI的开发者将首当其冲。通用性的软件工程（如web前后端）将是多米诺骨牌的第一张，其次是手机应用开发。VR及游戏等专才仍然安全。

阶段3：[软件即服务](https://www.zhihu.com/search?q=软件即服务&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})（SaaS）和无代码阶段（2-5年）失业率预测：75%

阶段2所遗留下的代码库已经重新被重写和更换。存留下来的代码库在测试覆盖率，安全性及标准化等各个方面都全面碾压前人。软件将不再需要文档。AI一直在基于用户的使用模式，优化自身。软件开发更关注业务本身，一句话就可以生成类似今日头条类的新闻推送系统。没人做全栈了，移动设备[app开发](https://www.zhihu.com/search?q=app开发&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})也消失了，开发者转向如机器人及生物技术等专业方向。不会编程的人士只要有好的业务想法，AI便可帮忙实现。

阶段4: 原生AI（5-10年）失业率预测：95%

这个阶段的代码不再由人类维护，单元测试和工程文档这类的事物也早都过时。AI代码并不需要使用人类能理解的汇编及高级语言。更原生的AI指令集会使得软硬件及编译器皆为AI所用，协同优化。写代码将会像公园里的[蒸汽火车](https://www.zhihu.com/search?q=蒸汽火车&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"618256622"})一样，仅仅是为了缅怀和记忆。

阶段5: 热寂（Heat Death）（10年以后）失业率预测：99%

软件早已无法识别。AI原生标准已经全球化。钢铁侠般的实验室里，AI会通过跟你聊天来完成你想要完成的任务。web 3.0也会在AI的推动下提前到来。

这些东西我们没法真正的预测，但对于底层软件工程师来说，写代码也仅仅只是最基础的环节。和硬件的交互，和各个流程的人沟通这些GAI都很难做到，我想，很多时候我们不能把我他以后发展真正的趋势，可以去拥抱他，先探索着利用他提升我们整体的效能。
